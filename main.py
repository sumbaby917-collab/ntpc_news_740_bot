import feedparser, requests, datetime, os, urllib.parse, time, re
from html import escape
import google.generativeai as genai

TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
GEMINI_KEY = os.getenv('GEMINI_API_KEY')

assert TELEGRAM_TOKEN, "ç¼ºå°‘ TELEGRAM_TOKEN"
assert CHAT_ID, "ç¼ºå°‘ TELEGRAM_CHAT_ID"

genai.configure(api_key=GEMINI_KEY)

MODEL_CANDIDATES = [
    "models/gemini-2.5-flash",
    "models/gemini-2.5-pro",
]

# -------------------------
# (A) æŸ¥è©¢ï¼šæ–°åŒ—å„ªå…ˆ + å…¨åœ‹æ“´æ•£ï¼ˆæ¯é¡åˆ¥å…©çµ„ï¼‰
# -------------------------
QUERY_POOLS = {
    "äº¤é€šæ”¿å‹™": {
        "ntpc": "æ–°åŒ— (äº¤é€šå®‰å…¨ OR è¡Œäºº OR é€šå­¸å·· OR äº‹æ•… OR é…’é§• OR æ·¡æ±Ÿå¤§æ©‹)",
        "national": "(äº¤é€šå®‰å…¨ OR è¡Œäººå®‰å…¨ OR é€šå­¸å·· OR äº‹æ•… OR é…’é§• OR è·¯å£æ”¹å–„)"
    },
    "æ•™è‚²æ¥­å‹™": {
        "ntpc": "æ–°åŒ— (è£œç¿’ç­ OR æœªç«‹æ¡ˆè£œç¿’ç­ OR èª²å¾Œç…§é¡§ OR çµ‚èº«å­¸ç¿’ OR æŠ€è·)",
        "national": "(è£œç¿’ç­ OR æœªç«‹æ¡ˆè£œç¿’ç­ OR èª²å¾Œç…§é¡§ OR çµ‚èº«å­¸ç¿’ OR æŠ€è·)"
    },
}

# -------------------------
# (B) ã€Œå…è¨±èˆŠèã€çš„æ›´æ–°ä¿¡è™Ÿï¼ˆå¯ä¾ä½ æ¥­å‹™å†å¢è£œï¼‰
# -------------------------
UPDATE_HINTS = [
    "æœ€æ–°", "æ›´æ–°", "çºŒ", "å†", "äºŒåº¦", "ç¬¬ä¸‰æ¬¡", "è¿½åŠ ", "åŠ é‡", "æ“´å¤§",
    "èµ·è¨´", "åˆ¤æ±º", "è£å®š", "åˆ¤åˆ‘", "ç§»é€", "å‹’ä»¤", "åœæ¥­", "æ’¤ç…§",
    "å†ç½°", "çºŒç½°", "ç´¯ç½°", "é‡ç½°", "ç¨½æŸ¥", "æŸ¥ç²", "é–‹ç½°"
]

NTPC_HINTS = ["æ–°åŒ—", "æ–°åŒ—å¸‚", "æ¿æ©‹", "æ–°èŠ", "ä¸­å’Œ", "æ°¸å’Œ", "ä¸‰é‡", "è˜†æ´²",
              "æ–°åº—", "åœŸåŸ", "æ¨¹æ—", "é¶¯æ­Œ", "ä¸‰å³½", "æ—å£", "æ·¡æ°´", "æ±æ­¢", "ç‘èŠ³"]

# -------------------------
# (C) æ™‚é–“åˆ¤æ–·ï¼šé è¨­åªæ”¶ 24hï¼›èˆŠèéœ€å…·æ›´æ–°ä¿¡è™Ÿæ‰æ”¾è¡Œ
# -------------------------
def get_entry_time_utc(entry):
    t = None
    if getattr(entry, "published_parsed", None):
        t = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=datetime.timezone.utc)
    elif getattr(entry, "updated_parsed", None):
        t = datetime.datetime.fromtimestamp(time.mktime(entry.updated_parsed), tz=datetime.timezone.utc)
    return t  # å¯èƒ½ç‚º None

def is_update_story(title: str) -> bool:
    return any(k in title for k in UPDATE_HINTS)

def is_recent_or_update(entry, hours=24) -> bool:
    t = get_entry_time_utc(entry)
    if t is None:
        # æ²’æ™‚é–“æˆ³ï¼šç‚ºé¿å…æ¼å ±ï¼Œå…ˆæ”¾è¡Œï¼Œä½†å¾Œé¢ä»æœƒé å»é‡èˆ‡é€£çµè§£ææ§åˆ¶å“è³ª
        return True
    now = datetime.datetime.now(datetime.timezone.utc)
    age = now - t
    if age <= datetime.timedelta(hours=hours):
        return True
    # è¶…é 24hï¼šåªæœ‰æ¨™é¡Œé¡¯ç¤ºã€Œæ›´æ–°/æ–°é€²åº¦ã€æ‰æ”¾è¡Œ
    return is_update_story(getattr(entry, "title", ""))

# -------------------------
# (D) é€£çµï¼šç¢ºå¯¦å°åˆ°åŸå§‹æ–°è
# -------------------------
def resolve_final_url(url: str) -> str:
    try:
        r = requests.get(url, timeout=12, allow_redirects=True, headers={"User-Agent": "Mozilla/5.0"})
        final_url = r.url
        # è‹¥ final_url æœ‰å¸¶ url= åƒæ•¸ï¼ˆå¸¸è¦‹æ–¼èšåˆå™¨ï¼‰ï¼Œå˜—è©¦å–å‡º
        parsed = urllib.parse.urlparse(final_url)
        qs = urllib.parse.parse_qs(parsed.query)
        if "url" in qs and qs["url"]:
            return qs["url"][0]
        return final_url
    except Exception:
        return url

def get_best_link(entry):
    # 1) RSS source href
    if getattr(entry, "source", None) and getattr(entry.source, "href", None):
        return entry.source.href

    # 2) links è£¡æ‰¾é news.google.com
    for l in getattr(entry, "links", []) or []:
        href = l.get("href")
        if href and "news.google.com" not in href:
            return href

    # 3) æœ€å¾Œç”¨ entry.link ä¸¦å˜—è©¦è·³è½‰è§£åŒ…
    return resolve_final_url(getattr(entry, "link", ""))

# -------------------------
# (E) æ–°åŒ—å„ªå…ˆæ’åºï¼šæ–°åŒ— > å…¶ä»–ï¼›å†ä¾æ™‚é–“æ–°è¿‘åº¦
# -------------------------
def is_ntpc_related(title: str) -> bool:
    return any(k in title for k in NTPC_HINTS)

def sort_key(entry):
    title = getattr(entry, "title", "")
    t = get_entry_time_utc(entry)
    # æ–°åŒ—å„ªå…ˆï¼šTrue æ’å‰é¢ -> ç”¨ 0/1
    ntpc_rank = 0 if is_ntpc_related(title) else 1
    # æ™‚é–“è¶Šæ–°è¶Šå‰ï¼šæ²’æœ‰æ™‚é–“å‰‡ç•¥é™æ¬Š
    if t is None:
        time_rank = 999999
    else:
        now = datetime.datetime.now(datetime.timezone.utc)
        time_rank = int((now - t).total_seconds())
    return (ntpc_rank, time_rank)

# -------------------------
# (F) AI æ‘˜è¦
# -------------------------
def get_ai_analysis(title):
    if not GEMINI_KEY:
        return "AIï¼šå°šæœªè¨­å®š GEMINI_API_KEYã€‚"

    prompt = (
        f"è«‹ä»¥æ–°åŒ—å¸‚æ”¿åºœæ•™è‚²å±€æ”¿ç­–æ²»ç†è¦–è§’ï¼Œ"
        f"é‡å°æ–°èæ¨™é¡Œç”¢å‡ºï¼š"
        f"ï¼ˆä¸€ï¼‰å…©å¥é‡é»æ‘˜è¦ï¼›ï¼ˆäºŒï¼‰ä¸€é …è¡Œæ”¿å› æ‡‰å»ºè­°ã€‚"
        f"èªæ°£æ­£å¼ã€å°ˆæ¥­ã€å¯ä¾›å±€å…§ç°¡å ±ã€‚\n"
        f"æ–°èæ¨™é¡Œï¼š{title}"
    )

    last_error = None
    for model_id in MODEL_CANDIDATES:
        try:
            model = genai.GenerativeModel(model_id)
            response = model.generate_content(prompt)
            if response and getattr(response, "text", None):
                return response.text.strip()
        except Exception as e:
            last_error = e
            continue

    return f"AIï¼šåˆ†ææš«æ™‚ç„¡æ³•ç”¢å‡ºï¼ˆ{type(last_error).__name__}ï¼‰"

# -------------------------
# (G) ç”¢ç”Ÿå ±å‘Šï¼šæ¯é¡åˆ¥åˆä½µ ntpc+nationalï¼Œå»é‡ã€éæ¿¾ã€æ’åºï¼Œå–å‰ 3
# -------------------------
def fetch_entries(query: str):
    safe_query = urllib.parse.quote_plus(query)
    rss_url = f"https://news.google.com/rss/search?q={safe_query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    feed = feedparser.parse(rss_url)
    return feed.entries or []

def generate_report():
    today = datetime.date.today().isoformat()
    report = f"ğŸ“‹ <b>æ•™è‚²è¼¿æƒ…å ±å‘Šï¼ˆæ–°åŒ—å„ªå…ˆï¼‹å…¨åœ‹å‹•æ…‹ï¼‰({today})</b>\n"
    report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"

    for label, pools in QUERY_POOLS.items():
        report += f"\nğŸ” <b>é¡åˆ¥ï¼š{escape(label)}</b>\n"

        entries = []
        entries += fetch_entries(pools["ntpc"])
        entries += fetch_entries(pools["national"])

        if not entries:
            report += "ä»Šæ—¥æš«ç„¡ç›¸é—œæ–°èã€‚\n"
            continue

        # 1) å…ˆåšã€Œæ–°/æ›´æ–°ã€éæ¿¾
        entries = [e for e in entries if is_recent_or_update(e, hours=24)]

        if not entries:
            report += "è¿‘ 24 å°æ™‚ï¼ˆå«æ›´æ–°é€²åº¦ï¼‰æœªç¯©é¸åˆ°ç¬¦åˆæ¢ä»¶ä¹‹æ–°èã€‚\n"
            continue

        # 2) å»é‡ï¼šç”¨ title + link ç²—ç•¥å»é‡
        seen = set()
        uniq = []
        for e in entries:
            title = getattr(e, "title", "").strip()
            link = getattr(e, "link", "").strip()
            key = (title, link)
            if key in seen:
                continue
            seen.add(key)
            uniq.append(e)

        # 3) æ–°åŒ—å„ªå…ˆ + è¶Šæ–°è¶Šå‰
        uniq.sort(key=sort_key)

        # 4) å–å‰ 3
        picked = 0
        for entry in uniq:
            title = getattr(entry, "title", "").strip()
            link = get_best_link(entry)
            analysis = get_ai_analysis(title)

            report += f"ğŸ“ <b>æ–°è</b>ï¼š{escape(title)}\n"
            report += f"ğŸ’¡ {escape(analysis)}\n"
            report += f"ğŸ”— <a href=\"{escape(link)}\">åŸæ–‡é€£çµ</a>\n"
            report += "--------------------\n"

            picked += 1
            if picked >= 3:
                break

        if picked == 0:
            report += "ä»Šæ—¥æš«ç„¡å¯ç”¨æ–°èï¼ˆå·²æ’é™¤èˆŠèä¸”ç„¡æ›´æ–°è€…ï¼‰ã€‚\n"

    return report

if __name__ == "__main__":
    final_report = generate_report()
    r = requests.post(
        f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
        data={
            "chat_id": CHAT_ID,
            "text": final_report,
            "parse_mode": "HTML",
            "disable_web_page_preview": True
        },
        timeout=20
    )
    if not r.ok:
        print("Telegram error:", r.status_code, r.text)
