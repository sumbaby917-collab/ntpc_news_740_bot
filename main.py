import os
import json
import time
import datetime
import traceback
import urllib.parse
import re
import requests
import feedparser

try:
    import google.generativeai as genai
except Exception:
    genai = None

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")

CACHE_FILE = "sent_cache.json"
CACHE_TTL_DAYS = 5

# æ¯é¡ï¼šç›®æ¨™æ•¸é‡ï¼ˆä¿åº•è‡³å°‘æœƒè£œåˆ° MIN_TOTALï¼‰
MAX_NTPC = 2
MAX_OTHER = 2
MIN_TOTAL = 3  # æ¯é¡è‡³å°‘ 3 å‰‡ï¼ˆä¸è¶³å°±ä¸åˆ†æ¬„è£œè¶³ï¼‰

TG_MAX_CHARS = 3500

def html_escape(s: str) -> str:
    if s is None:
        return ""
    return (s.replace("&", "&amp;")
             .replace("<", "&lt;")
             .replace(">", "&gt;")
             .replace("\"", "&quot;"))

def load_cache():
    try:
        if os.path.exists(CACHE_FILE):
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                d = json.load(f)
            return d if isinstance(d, dict) else {}
    except Exception:
        pass
    return {}

def save_cache(cache: dict):
    try:
        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(cache if isinstance(cache, dict) else {}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def prune_cache(cache: dict):
    now = int(time.time())
    ttl = CACHE_TTL_DAYS * 86400
    for k in list(cache.keys()):
        ts = cache.get(k, {}).get("ts", 0)
        if ts and now - ts > ttl:
            cache.pop(k, None)

def send_telegram_once(text: str):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        print("âŒ Missing Telegram secrets")
        return False

    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    r = requests.post(url, data=payload, timeout=25)
    print("Telegram status:", r.status_code)
    if not r.ok:
        print("Telegram error:", r.text[:900])
        return False
    return True

def send_telegram_chunked(full_text: str):
    parts = full_text.split("\n\n")
    chunks, buf = [], ""
    for p in parts:
        candidate = (buf + "\n\n" + p) if buf else p
        if len(candidate) <= TG_MAX_CHARS:
            buf = candidate
        else:
            if buf:
                chunks.append(buf)
            if len(p) > TG_MAX_CHARS:
                for i in range(0, len(p), TG_MAX_CHARS):
                    chunks.append(p[i:i+TG_MAX_CHARS])
                buf = ""
            else:
                buf = p
    if buf:
        chunks.append(buf)

    ok_all = True
    for i, c in enumerate(chunks, start=1):
        prefix = f"ï¼ˆç¬¬ {i}/{len(chunks)} å‰‡ï¼‰\n" if len(chunks) > 1 else ""
        ok_all = send_telegram_once(prefix + c) and ok_all
        time.sleep(1.2)
    return ok_all

def safe_get(url):
    try:
        return requests.get(url, timeout=12, allow_redirects=True, headers={"User-Agent": "Mozilla/5.0"})
    except Exception:
        return None

def extract_external_url_from_html(html: str):
    if not html:
        return None
    candidates = re.findall(r'href="(https?://[^"]+)"', html)
    for u in candidates:
        if any(bad in u for bad in ["news.google.com", "accounts.google.com", "policies.google.com", "support.google.com", "google.com"]):
            continue
        return u
    return None

def resolve_to_canonical_url(url: str) -> str:
    if not url:
        return url
    r = safe_get(url)
    if not r:
        return url
    final = r.url
    if "news.google.com" not in final:
        return final
    ext = extract_external_url_from_html(r.text)
    return ext or final

def fetch_entries(query: str, limit=24):
    q = urllib.parse.quote_plus(query)
    rss = f"https://news.google.com/rss/search?q={q}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    feed = feedparser.parse(rss)
    return (feed.entries or [])[:limit]

NTPC_HINTS = [
    "æ–°åŒ—", "æ–°åŒ—å¸‚", "ä¾¯å‹å®œ", "æ¿æ©‹", "æ–°èŠ", "ä¸­å’Œ", "æ°¸å’Œ", "ä¸‰é‡", "è˜†æ´²",
    "æ–°åº—", "åœŸåŸ", "æ¨¹æ—", "é¶¯æ­Œ", "ä¸‰å³½", "æ—å£", "æ·¡æ°´", "æ±æ­¢", "ç‘èŠ³", "æ³°å±±", "äº”è‚¡"
]

def is_ntpc(title: str) -> bool:
    t = title or ""
    return any(k in t for k in NTPC_HINTS)

# âŒ æ’é™¤ä½ ä¸æƒ³è¦çš„ã€Œå±…å®¶/é†«ç™‚äº‹æ•…ã€èªæ„ï¼ˆå¯å†æ“´ï¼‰
TRAFFIC_EXCLUDE = ["ä¸€æ°§åŒ–ç¢³", "ä¸­æ¯’", "ç“¦æ–¯", "çŒæ­»", "æ€¥è¨º", "é€é†«", "å®¶ä¸­", "å±…å®¶"]

def is_traffic_relevant(title: str) -> bool:
    if any(x in (title or "") for x in TRAFFIC_EXCLUDE):
        return False
    return True

def rule_based_advice(category: str) -> str:
    if "äº¤é€š" in category:
        return "å»ºè­°ä»¥é€šå­¸ç’°å¢ƒèˆ‡äº‹æ•…ç†±é»ç‚ºæ²»ç†å–®ä½ï¼Œå¼·åŒ–å·¥ç¨‹æ”¹å–„ã€é•è¦åŸ·æ³•èˆ‡æ ¡åœ’å®£å°ä¹‹å”åŒï¼Œä¸¦ä»¥KPIæ»¾å‹•è¿½è¹¤æˆæ•ˆã€‚"
    if "çµ‚èº«" in category:
        return "å»ºè­°ä»¥å ´åŸŸè§¸åŠèˆ‡å­¸ç¿’æˆæ•ˆç‚ºæ ¸å¿ƒï¼Œæ·±åŒ–ç¤¾å¤§/æ¨‚é½¡èˆ‡åœ¨åœ°åˆä½œï¼Œå»ºç«‹èª²ç¨‹å“è³ªèˆ‡å¼±å‹¢å‹å–„é…å¥—ï¼Œæå‡çºŒå­¸ç‡ã€‚"
    return "å»ºè­°æ¡é¢¨éšªå°å‘ç¨½æŸ¥èˆ‡è³‡è¨Šé€æ˜ä¸¦é€²ï¼Œé–å®šæœªç«‹æ¡ˆèˆ‡é‡å¤§çˆ­è­°æ¡ˆä»¶ï¼Œå¼·åŒ–è·¨æ©Ÿé—œè¯ç¨½èˆ‡å®¶é•·è­˜åˆ¥å®£å°ï¼Œé™ä½å¤–æº¢é¢¨éšªã€‚"

def ai_advice(category: str, ntpc_titles: list, other_titles: list) -> str:
    if (not GEMINI_KEY) or (genai is None):
        return rule_based_advice(category)
    try:
        genai.configure(api_key=GEMINI_KEY)
        model = genai.GenerativeModel("gemini-1.5-flash")
        titles_block = ""
        if ntpc_titles:
            titles_block += "ã€æ–°åŒ—ã€‘\n" + "\n".join([f"- {t}" for t in ntpc_titles[:3]]) + "\n"
        if other_titles:
            titles_block += "ã€å¤–ç¸£å¸‚/å…¨åœ‹ã€‘\n" + "\n".join([f"- {t}" for t in other_titles[:3]]) + "\n"
        prompt = (
            "ä½ æ˜¯æ–°åŒ—å¸‚æ”¿åºœæ•™è‚²å±€æ”¿ç­–æ²»ç†å¹•åƒšã€‚è«‹ç”¢å‡º2-3å¥è¡Œæ”¿å› æ‡‰å»ºè­°ï¼Œå…·é«”å¯åŸ·è¡Œã€å¯è·¨å±€è™•å”ä½œã€‚\n\n"
            f"é¡åˆ¥ï¼š{category}\n{titles_block}"
        )
        resp = model.generate_content(prompt)
        if resp and getattr(resp, "text", None):
            return resp.text.strip()[:260]
        return rule_based_advice(category)
    except Exception as e:
        print("AI soft-fail:", type(e).__name__, str(e)[:120])
        return rule_based_advice(category)

# âœ… æŸ¥è©¢æ”¹æˆã€Œæ›´åƒä½ è¦çš„æ²»ç†èªæ„ã€
QUERY_POOLS = {
    "ğŸš¦ äº¤é€šå®‰å…¨": {
        "ntpc": "æ–°åŒ— (è¡Œäºº OR é€šå­¸å·· OR è·¯å£ OR æ–‘é¦¬ç·š OR æ ¡åœ’å‘¨é‚Š OR äº¤é€šåŸ·æ³• OR é“è·¯å·¥ç¨‹ OR äº‹æ•…)",
        "national": "(è¡Œäºº OR é€šå­¸å·· OR è·¯å£ OR æ–‘é¦¬ç·š OR æ ¡åœ’å‘¨é‚Š OR äº¤é€šåŸ·æ³• OR é“è·¯å·¥ç¨‹ OR äº‹æ•…)"
    },
    "ğŸ“š çµ‚èº«å­¸ç¿’": {
        "ntpc": "æ–°åŒ— (çµ‚èº«å­¸ç¿’ OR ç¤¾å€å¤§å­¸ OR æ¨‚é½¡å­¸ç¿’ OR å­¸ç¿’å‹åŸå¸‚ OR å…¬æ°‘èª²ç¨‹)",
        "national": "(çµ‚èº«å­¸ç¿’ OR ç¤¾å€å¤§å­¸ OR æ¨‚é½¡å­¸ç¿’ OR å­¸ç¿’å‹åŸå¸‚ OR å…¬æ°‘èª²ç¨‹)"
    },
    "ğŸ« è£œæ•™é¡ï¼ˆè£œç¿’ç­ï¼‰": {
        "ntpc": "æ–°åŒ— (è£œç¿’ç­ OR æœªç«‹æ¡ˆè£œç¿’ç­ OR è£œç¿’ç­ç¨½æŸ¥ OR æ¶ˆè²»çˆ­è­° OR é€€è²» OR ä¸ç•¶å°å¾…)",
        "national": "(è£œç¿’ç­ OR æœªç«‹æ¡ˆè£œç¿’ç­ OR è£œç¿’ç­ç¨½æŸ¥ OR æ¶ˆè²»çˆ­è­° OR é€€è²» OR ä¸ç•¶å°å¾…)"
    }
}

def build_line(title: str, link: str) -> str:
    safe_title = html_escape(title)
    safe_link = html_escape(link) if link else ""
    return f'â€¢ <a href="{safe_link}">{safe_title}</a>' if safe_link else f"â€¢ {safe_title}"

def main():
    print("=== START ===", datetime.datetime.now().isoformat())
    cache = load_cache()
    prune_cache(cache)

    today = datetime.date.today().isoformat()
    blocks = []

    for category, pools in QUERY_POOLS.items():
        entries = fetch_entries(pools["ntpc"], limit=30) + fetch_entries(pools["national"], limit=30)

        ntpc_lines, other_lines = [], []
        ntpc_titles, other_titles = [], []
        fallback_lines, fallback_titles = [], []

        seen_local = set()

        for e in entries:
            title = (getattr(e, "title", "") or "").strip()
            raw_link = getattr(e, "link", "") or ""

            # é¡åˆ¥èªæ„éæ¿¾ï¼ˆäº¤é€šæ’é™¤å±…å®¶ä¸­æ¯’ï¼‰
            if "äº¤é€š" in category and not is_traffic_relevant(title):
                continue

            link = resolve_to_canonical_url(raw_link)
            # å»é‡ keyï¼šå„ªå…ˆç”¨ linkï¼›æ²’æœ‰ link æ‰ç”¨ title
            key = link if link else title
            if not key or key in seen_local:
                continue
            seen_local.add(key)

            cache_key = link if link else f"title::{title}"
            if cache_key in cache:
                continue

            # ç¬¬ä¸€éšæ®µï¼šåˆ†æ¬„å¡«æ»¿
            if is_ntpc(title) and len(ntpc_lines) < MAX_NTPC:
                ntpc_lines.append(build_line(title, link))
                ntpc_titles.append(title)
                cache[cache_key] = {"ts": int(time.time())}
                continue

            if (not is_ntpc(title)) and len(other_lines) < MAX_OTHER:
                other_lines.append(build_line(title, link))
                other_titles.append(title)
                cache[cache_key] = {"ts": int(time.time())}
                continue

            # ç¬¬äºŒéšæ®µï¼šä¿åº•è£œè¶³ï¼ˆä¸é™æ–°åŒ—/å¤–ç¸£å¸‚ï¼‰
            if len(fallback_lines) < MIN_TOTAL:
                fallback_lines.append(build_line(title, link))
                fallback_titles.append(title)
                cache[cache_key] = {"ts": int(time.time())}

            # æå‰åœæ­¢æ¢ä»¶ï¼šåˆ†æ¬„éƒ½æ»¿ + ä¿åº•ä¹Ÿå¤ 
            if len(ntpc_lines) >= MAX_NTPC and len(other_lines) >= MAX_OTHER and len(fallback_lines) >= MIN_TOTAL:
                break

        # å¦‚æœæŸä¸€é‚Šå¤ªå°‘ï¼Œç”¨ä¿åº•è£œè¶³ï¼ˆé¿å…ç©ºåˆ°ä¸åˆç†ï¼‰
        # å…ˆæŠŠä¿åº•åˆ†é…åˆ°ç¼ºå£
        def fill_missing(target_list, needed):
            while len(target_list) < needed and fallback_lines:
                target_list.append(fallback_lines.pop(0))

        fill_missing(ntpc_lines, 1)  # è‡³å°‘ 1
        fill_missing(other_lines, 1) # è‡³å°‘ 1

        advice = ai_advice(category, ntpc_titles, other_titles)

        block = f"<b>{html_escape(category)}</b>\n"
        block += "ğŸŸ¦ <b>æ–°åŒ—</b>\n" + ("\n".join(ntpc_lines) if ntpc_lines else "ï¼ˆæœ¬è¼ªæœªç¯©é¸åˆ°ç¬¦åˆæ¢ä»¶ä¹‹æ–°åŒ—æ–°èï¼‰") + "\n\n"
        block += "ğŸŸ¨ <b>å¤–ç¸£å¸‚ï¼å…¨åœ‹</b>\n" + ("\n".join(other_lines) if other_lines else "ï¼ˆæœ¬è¼ªæœªç¯©é¸åˆ°ç¬¦åˆæ¢ä»¶ä¹‹å…¶ä»–ç¸£å¸‚/å…¨åœ‹æ–°èï¼‰") + "\n\n"
        block += f"ğŸ’¡ <b>è¡Œæ”¿å› æ‡‰å»ºè­°ï¼ˆsoft-failï¼‰</b>\n{html_escape(advice)}"
        blocks.append(block)

    header = f"ğŸ— <b>æ–°åŒ—å¸‚æ•™è‚²èˆ‡äº¤é€šè¼¿æƒ…æ™¨å ±</b>\næ—¥æœŸï¼š{today}"
    full_msg = header + "\n\n" + "\n\n".join(blocks)

    send_telegram_chunked(full_msg)
    save_cache(cache)
    print("=== END ===")

if __name__ == "__main__":
    try:
        main()
    except Exception:
        traceback.print_exc()
        raise SystemExit(0)
