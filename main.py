import os
import json
import time
import datetime
import traceback
import urllib.parse
import re
import requests
import feedparser

# ï¼ˆå¯é¸ï¼‰AIï¼šGeminiï¼ˆsoft-failï¼‰
try:
    import google.generativeai as genai
except Exception:
    genai = None

# =========================
# åŸºæœ¬è¨­å®š
# =========================
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")

CACHE_FILE = "sent_cache.json"
CACHE_TTL_DAYS = 7

MAX_NTPC = 3
MAX_OTHER = 3

# Telegram é™åˆ¶ 4096ï¼›ä¿å®ˆåˆ‡ 3500
TG_MAX_CHARS = 3500

# =========================
# HTML Escape
# =========================
def html_escape(s: str) -> str:
    if s is None:
        return ""
    return (
        s.replace("&", "&amp;")
         .replace("<", "&lt;")
         .replace(">", "&gt;")
         .replace("\"", "&quot;")
    )

# =========================
# Cache
# =========================
def load_cache():
    try:
        if os.path.exists(CACHE_FILE):
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            return data if isinstance(data, dict) else {}
    except Exception:
        pass
    return {}

def save_cache(cache: dict):
    try:
        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(cache if isinstance(cache, dict) else {}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def prune_cache(cache: dict):
    now = int(time.time())
    ttl = CACHE_TTL_DAYS * 86400
    for k in list(cache.keys()):
        ts = cache.get(k, {}).get("ts", 0)
        if ts and now - ts > ttl:
            cache.pop(k, None)

# =========================
# Telegramï¼ˆåˆ†æ®µé€å‡ºï¼‰
# =========================
def send_telegram_once(text: str):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        print("âŒ Missing TELEGRAM_TOKEN or TELEGRAM_CHAT_ID")
        return False

    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    try:
        r = requests.post(url, data=payload, timeout=25)
        print("Telegram status:", r.status_code)
        if not r.ok:
            print("Telegram error:", r.text[:900])
            return False
        return True
    except Exception as e:
        print("Telegram exception:", type(e).__name__, str(e)[:200])
        return False

def send_telegram_chunked(full_text: str):
    # ä¾æ®µè½åˆ‡ï¼šç”¨é›™æ›è¡Œä½œåˆ†éš”ï¼Œé¿å…åˆ‡å£ HTML tag
    parts = full_text.split("\n\n")
    chunks = []
    buf = ""

    for p in parts:
        candidate = (buf + "\n\n" + p) if buf else p
        if len(candidate) <= TG_MAX_CHARS:
            buf = candidate
        else:
            if buf:
                chunks.append(buf)
            # è‹¥å–®æ®µå°±è¶…é•·ï¼Œç¡¬åˆ‡ï¼ˆæ¥µå°‘è¦‹ï¼‰
            if len(p) > TG_MAX_CHARS:
                for i in range(0, len(p), TG_MAX_CHARS):
                    chunks.append(p[i:i+TG_MAX_CHARS])
                buf = ""
            else:
                buf = p
    if buf:
        chunks.append(buf)

    ok_all = True
    for i, c in enumerate(chunks, start=1):
        prefix = ""
        if len(chunks) > 1:
            prefix = f"ï¼ˆç¬¬ {i}/{len(chunks)} å‰‡ï¼‰\n"
        ok = send_telegram_once(prefix + c)
        ok_all = ok_all and ok
        time.sleep(1.2)  # é¿å…é€å¤ªå¿«è§¸ç™¼é™åˆ¶
    return ok_all

# =========================
# HTTP helper
# =========================
def safe_get(url):
    try:
        return requests.get(url, timeout=12, allow_redirects=True, headers={"User-Agent": "Mozilla/5.0"})
    except Exception as e:
        print("WARN safe_get:", type(e).__name__, str(e)[:120])
        return None

# =========================
# Google News â†’ åŸå§‹æ–°èé€£çµ
# =========================
def extract_external_url_from_html(html: str):
    if not html:
        return None
    candidates = re.findall(r'href="(https?://[^"]+)"', html)
    for u in candidates:
        # é¿é–‹ google è‡ªèº«é€£çµ
        if any(bad in u for bad in ["news.google.com", "accounts.google.com", "policies.google.com", "support.google.com", "google.com"]):
            continue
        return u
    m = re.search(r"[?&]url=(https?%3A%2F%2F[^&]+)", html)
    if m:
        return urllib.parse.unquote(m.group(1))
    return None

def resolve_to_canonical_url(url: str) -> str:
    if not url:
        return url
    r = safe_get(url)
    if not r:
        return url

    final_url = r.url
    if "news.google.com" not in final_url:
        parsed = urllib.parse.urlparse(final_url)
        qs = urllib.parse.parse_qs(parsed.query)
        if "url" in qs and qs["url"]:
            return qs["url"][0]
        return final_url

    ext = extract_external_url_from_html(r.text)
    return ext or final_url

# =========================
# RSS
# =========================
def fetch_entries(query: str, limit=16):
    q = urllib.parse.quote_plus(query)
    rss = f"https://news.google.com/rss/search?q={q}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    try:
        feed = feedparser.parse(rss)
        return (feed.entries or [])[:limit]
    except Exception as e:
        print("WARN feedparser:", type(e).__name__, str(e)[:120])
        return []

# =========================
# æ–°åŒ—è¾¨è­˜
# =========================
NTPC_HINTS = [
    "æ–°åŒ—", "æ–°åŒ—å¸‚", "ä¾¯å‹å®œ", "æ¿æ©‹", "æ–°èŠ", "ä¸­å’Œ", "æ°¸å’Œ", "ä¸‰é‡", "è˜†æ´²",
    "æ–°åº—", "åœŸåŸ", "æ¨¹æ—", "é¶¯æ­Œ", "ä¸‰å³½", "æ—å£", "æ·¡æ°´", "æ±æ­¢", "ç‘èŠ³", "æ³°å±±", "äº”è‚¡"
]

def is_ntpc(title: str) -> bool:
    t = title or ""
    return any(k in t for k in NTPC_HINTS)

# =========================
# è¦å‰‡å‹å»ºè­°ï¼ˆAI å¤±æ•—å‚™æ´ï¼‰
# =========================
def rule_based_advice(category: str) -> str:
    if "äº¤é€š" in category:
        return "å»ºè­°ä»¥äº‹æ•…ç†±é»/é€šå­¸å··ç‚ºæ²»ç†å–®å…ƒï¼Œæ¨é€²å·¥ç¨‹æ”¹å–„ã€é•è¦ç†±å€åŸ·æ³•èˆ‡æ ¡åœ’å®£å°ä¸€é«”åŒ–ï¼Œä¸¦ä»¥KPIæ»¾å‹•è¿½è¹¤æˆæ•ˆã€‚"
    if "çµ‚èº«" in category:
        return "å»ºè­°ä»¥å ´åŸŸè§¸åŠèˆ‡å­¸ç¿’æˆæ•ˆç‚ºæ ¸å¿ƒï¼Œæ·±åŒ–ç¤¾å¤§/æ¨‚é½¡èˆ‡åœ¨åœ°å•†åœˆå”ä½œï¼Œå»ºç«‹èª²ç¨‹å“è³ªèˆ‡å¼±å‹¢å‹å–„é…å¥—ï¼Œæå‡çºŒå­¸ç‡ã€‚"
    return "å»ºè­°æ¡é¢¨éšªå°å‘ç¨½æŸ¥èˆ‡è³‡è¨Šé€æ˜ä¸¦é€²ï¼Œé–å®šæœªç«‹æ¡ˆèˆ‡é‡å¤§çˆ­è­°æ¡ˆä»¶ï¼Œå¼·åŒ–è·¨æ©Ÿé—œè¯ç¨½èˆ‡å®¶é•·è­˜åˆ¥å®£å°ï¼Œé™ä½å¤–æº¢é¢¨éšªã€‚"

def ai_advice(category: str, ntpc_titles: list, other_titles: list) -> str:
    if (not GEMINI_KEY) or (genai is None):
        return rule_based_advice(category)

    try:
        genai.configure(api_key=GEMINI_KEY)

        titles_block = ""
        if ntpc_titles:
            titles_block += "ã€æ–°åŒ—ã€‘\n" + "\n".join([f"- {t}" for t in ntpc_titles[:3]]) + "\n"
        if other_titles:
            titles_block += "ã€å¤–ç¸£å¸‚/å…¨åœ‹ã€‘\n" + "\n".join([f"- {t}" for t in other_titles[:3]]) + "\n"

        prompt = (
            "ä½ æ˜¯æ–°åŒ—å¸‚æ”¿åºœæ•™è‚²å±€æ”¿ç­–æ²»ç†å¹•åƒšã€‚"
            "è«‹é‡å°ä¸‹åˆ—æ–°èæ¨™é¡Œï¼Œç”¢å‡ºã€Œ2-3å¥ã€è¡Œæ”¿å› æ‡‰å»ºè­°ï¼Œ"
            "è¦å…·é«”å¯åŸ·è¡Œã€å¯è·¨å±€è™•å”ä½œã€èªæ°£æ­£å¼å°ˆæ¥­ï¼Œé¿å…ç©ºæ³›ã€‚\n\n"
            f"é¡åˆ¥ï¼š{category}\n{titles_block}"
        )

        # ç›¡é‡ç”¨ä½ åŸæœ¬å¯ç”¨çš„æ¨¡å‹åï¼ˆé¿å… 404ï¼‰
        model = genai.GenerativeModel("gemini-1.5-flash")
        resp = model.generate_content(prompt)
        if resp and getattr(resp, "text", None):
            return resp.text.strip()[:260]
        return rule_based_advice(category)

    except Exception as e:
        print("AI advice soft-fail:", type(e).__name__, str(e)[:160])
        return rule_based_advice(category)

# =========================
# æŸ¥è©¢æ± ï¼šæ–°åŒ—å„ªå…ˆ + å…¨åœ‹è£œå……
# =========================
QUERY_POOLS = {
    "ğŸš¦ äº¤é€šå®‰å…¨": {
        "ntpc": "æ–°åŒ— (äº¤é€šå®‰å…¨ OR è¡Œäºº OR é€šå­¸å·· OR äº‹æ•… OR é…’é§• OR è·¯å£)",
        "national": "(äº¤é€šå®‰å…¨ OR è¡Œäººå®‰å…¨ OR é€šå­¸å·· OR äº‹æ•… OR é…’é§• OR è·¯å£æ”¹å–„)"
    },
    "ğŸ“š çµ‚èº«å­¸ç¿’": {
        "ntpc": "æ–°åŒ— (çµ‚èº«å­¸ç¿’ OR ç¤¾å€å¤§å­¸ OR æ¨‚é½¡å­¸ç¿’ OR å­¸ç¿’å‹åŸå¸‚)",
        "national": "(çµ‚èº«å­¸ç¿’ OR ç¤¾å€å¤§å­¸ OR æ¨‚é½¡å­¸ç¿’ OR å­¸ç¿’å‹åŸå¸‚)"
    },
    "ğŸ« è£œæ•™é¡ï¼ˆè£œç¿’ç­ï¼‰": {
        "ntpc": "æ–°åŒ— (è£œç¿’ç­ OR æœªç«‹æ¡ˆè£œç¿’ç­ OR èª²å¾Œç…§é¡§ OR æ‰è—ç­)",
        "national": "(è£œç¿’ç­ OR æœªç«‹æ¡ˆè£œç¿’ç­ OR èª²å¾Œç…§é¡§ OR æ‰è—ç­)"
    }
}

# =========================
# ä¸»æµç¨‹
# =========================
def main():
    print("=== Daily Report Bot START ===", datetime.datetime.now().isoformat())
    print("Has TELEGRAM_TOKEN:", bool(TELEGRAM_TOKEN))
    print("Has TELEGRAM_CHAT_ID:", bool(TELEGRAM_CHAT_ID))
    print("Has GEMINI_API_KEY:", bool(GEMINI_KEY))

    cache = load_cache()
    prune_cache(cache)

    today = datetime.date.today().isoformat()
    blocks = []

    for category, pools in QUERY_POOLS.items():
        entries = fetch_entries(pools["ntpc"], limit=18) + fetch_entries(pools["national"], limit=18)

        ntpc_lines, other_lines = [], []
        ntpc_titles, other_titles = [], []
        seen_local = set()

        for e in entries:
            title = (getattr(e, "title", "") or "").strip()
            raw_link = getattr(e, "link", "") or ""
            link = resolve_to_canonical_url(raw_link)

            key = link if link else title
            if not key or key in seen_local:
                continue
            seen_local.add(key)

            cache_key = link if link else f"title::{title}"
            if cache_key in cache:
                continue

            safe_title = html_escape(title)
            safe_link = html_escape(link) if link else ""

            line = f'â€¢ <a href="{safe_link}">{safe_title}</a>' if safe_link else f"â€¢ {safe_title}"

            if is_ntpc(title):
                if len(ntpc_lines) < MAX_NTPC:
                    ntpc_lines.append(line)
                    ntpc_titles.append(title)
                    cache[cache_key] = {"ts": int(time.time())}
            else:
                if len(other_lines) < MAX_OTHER:
                    other_lines.append(line)
                    other_titles.append(title)
                    cache[cache_key] = {"ts": int(time.time())}

            if len(ntpc_lines) >= MAX_NTPC and len(other_lines) >= MAX_OTHER:
                break

        advice = ai_advice(category, ntpc_titles, other_titles)

        block = f"<b>{html_escape(category)}</b>\n"
        block += "ğŸŸ¦ <b>æ–°åŒ—</b>\n" + ("\n".join(ntpc_lines) if ntpc_lines else "ï¼ˆæœ¬è¼ªæœªç¯©é¸åˆ°ç¬¦åˆæ¢ä»¶ä¹‹æ–°åŒ—æ–°èï¼‰") + "\n\n"
        block += "ğŸŸ¨ <b>å¤–ç¸£å¸‚ï¼å…¨åœ‹</b>\n" + ("\n".join(other_lines) if other_lines else "ï¼ˆæœ¬è¼ªæœªç¯©é¸åˆ°ç¬¦åˆæ¢ä»¶ä¹‹å…¶ä»–ç¸£å¸‚/å…¨åœ‹æ–°èï¼‰") + "\n\n"
        block += f"ğŸ’¡ <b>è¡Œæ”¿å› æ‡‰å»ºè­°ï¼ˆsoft-failï¼‰</b>\n{html_escape(advice)}"

        blocks.append(block)

    header = f"ğŸ— <b>æ–°åŒ—å¸‚æ•™è‚²èˆ‡äº¤é€šè¼¿æƒ…æ™¨å ±</b>\næ—¥æœŸï¼š{today}"
    full_msg = header + "\n\n" + "\n\n".join(blocks)

    ok = send_telegram_chunked(full_msg)
    print("Telegram overall ok:", ok)

    save_cache(cache)
    print("=== Daily Report Bot END ===")

if __name__ == "__main__":
    try:
        main()
    except Exception:
        traceback.print_exc()
        # ä¿æŒ workflow ç¶ å‹¾
        raise SystemExit(0)
