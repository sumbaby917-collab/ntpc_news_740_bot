import feedparser, requests, datetime, os, urllib.parse, time
from html import escape

import google.generativeai as genai

TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
GEMINI_KEY = os.getenv('GEMINI_API_KEY')

assert TELEGRAM_TOKEN, "ç¼ºå°‘ TELEGRAM_TOKEN"
assert CHAT_ID, "ç¼ºå°‘ TELEGRAM_CHAT_ID"

genai.configure(api_key=GEMINI_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')  # è‹¥ä½ å¸³è™Ÿä¸æ”¯æ´æœƒå ±éŒ¯ï¼ŒéŒ¯èª¤æœƒåœ¨ä¸‹æ–¹é¡¯ç¤º

KEYWORDS = {
    "äº¤é€šæ”¿å‹™": "æ–°åŒ— (äº¤é€šå®‰å…¨ OR é€šå­¸å·· OR æ·¡æ±Ÿå¤§æ©‹ OR äº‹æ•… OR è¡Œäºº) ",
    "æ•™è‚²æ¥­å‹™": "æ–°åŒ— (è£œç¿’ç­ OR çµ‚èº«å­¸ç¿’ OR èª²å¾Œç…§é¡§ OR å®‰è¦ª OR æŠ€è·) ",
}

def get_best_link(entry):
    # å˜—è©¦æ‰¾é news.google.com çš„ä¾†æºé€£çµ
    if hasattr(entry, "source") and entry.source and hasattr(entry.source, "href"):
        return entry.source.href
    if hasattr(entry, "links"):
        for l in entry.links:
            href = l.get("href")
            if href and "news.google.com" not in href:
                return href
    return entry.link

def within_last_hours(entry, hours=24):
    now = datetime.datetime.utcnow()
    t = None
    if hasattr(entry, "published_parsed") and entry.published_parsed:
        t = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed))
    elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
        t = datetime.datetime.fromtimestamp(time.mktime(entry.updated_parsed))
    if not t:
        return True  # æ²’æ™‚é–“æˆ³å°±å…ˆæ”¾è¡Œ
    return (now - t) <= datetime.timedelta(hours=hours)

def get_ai_analysis(title):
    if not GEMINI_KEY:
        return "AIï¼šæœªåµæ¸¬åˆ° GEMINI_API_KEYã€‚"
    prompt = f"ä½ æ˜¯ä¸€ä½æ–°åŒ—æ•™è‚²å±€å®˜å“¡ï¼Œè«‹é‡å°æ–°èã€Œ{title}ã€ç”¢å‡ºå…©å¥æ‘˜è¦èˆ‡ä¸€é …å»ºè­°ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡ã€‚"
    try:
        resp = model.generate_content(prompt)
        return (resp.text or "").strip() or "AIï¼šæœªç”¢å‡ºæ–‡æœ¬ã€‚"
    except Exception as e:
        return f"AIï¼šç”Ÿæˆå¤±æ•—ï¼ˆ{type(e).__name__}ï¼š{e}ï¼‰"

def generate_report():
    today = datetime.date.today().isoformat()
    report = f"ğŸ“‹ <b>æ•™è‚²è¼¿æƒ…å ±å‘Šï¼ˆæ–°åŒ—æ ¸å¿ƒï¼‹å…¨åœ‹å‹•æ…‹ï¼‰({today})</b>\n"
    report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"

    for label, query in KEYWORDS.items():
        report += f"\nğŸ” <b>é¡åˆ¥ï¼š{escape(label)}</b>\n"

        safe_query = urllib.parse.quote_plus(query)
        rss_url = f"https://news.google.com/rss/search?q={safe_query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
        feed = feedparser.parse(rss_url)

        if not feed.entries:
            report += "ä»Šæ—¥æš«ç„¡ç›¸é—œæ–°èã€‚\n"
            continue

        seen = set()
        picked = 0
        for entry in feed.entries:
            if not within_last_hours(entry, 24):
                continue
            title = entry.title.strip()
            if title in seen:
                continue
            seen.add(title)

            url = get_best_link(entry)
            analysis = get_ai_analysis(title)

            report += f"ğŸ“ <b>æ–°è</b>ï¼š{escape(title)}\n"
            report += f"ğŸ’¡ {escape(analysis)}\n"
            report += f"ğŸ”— <a href=\"{escape(url)}\">åŸæ–‡é€£çµ</a>\n"
            report += "--------------------\n"

            picked += 1
            if picked >= 3:
                break

        if picked == 0:
            report += "è¿‘24å°æ™‚æœªç¯©åˆ°ç¬¦åˆæ¢ä»¶ä¹‹æ–°èã€‚\n"

    return report

if __name__ == "__main__":
    final_report = generate_report()
    r = requests.post(
        f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
        data={
            "chat_id": CHAT_ID,
            "text": final_report,
            "parse_mode": "HTML",
            "disable_web_page_preview": True
        },
        timeout=20
    )
    # è‹¥å¤±æ•—ï¼Œå°å‡ºåŸå› æ–¹ä¾¿ä½ åœ¨ logs ç›´æ¥çœ‹åˆ°
    if not r.ok:
        print("Telegram error:", r.status_code, r.text)
